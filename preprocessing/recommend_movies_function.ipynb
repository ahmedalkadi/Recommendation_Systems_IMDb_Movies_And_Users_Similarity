{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMED OSAMA\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# import the datasets\n",
    "user_movies=pd.read_csv(\"user_movies.csv\")\n",
    "rating_history_norm=pd.read_csv(\"rating_history_norm.csv\",index_col=0)\n",
    "with open('one_hot_encoder_sec.pkl', 'rb') as f:\n",
    "    active_ohe = pickle.load(f)\n",
    "\n",
    "\n",
    "# Factorisation machines class\n",
    "class FactorizationMachine(torch.nn.Module):\n",
    "    def __init__(self, n, k, bias=False):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.linear = torch.nn.Linear(self.n, 1, bias)\n",
    "        self.V = torch.nn.Parameter(torch.randn(n, k))  \n",
    "    def forward(self, x_batch):\n",
    "        part_1 = torch.sum(torch.mm(x_batch, self.V).pow(2))\n",
    "        part_2 = torch.sum(torch.mm(x_batch.pow(2), self.V.pow(2)))\n",
    "        inter_term = 0.5 * (part_1 - part_2)\n",
    "        var_strength = self.linear(x_batch)\n",
    "        return var_strength + inter_term\n",
    "    \n",
    "\n",
    "# initialize the model\n",
    "model=FactorizationMachine(n=29721, k=20)\n",
    "model.load_state_dict(torch.load('model_cola.pt'))\n",
    "\n",
    "\n",
    "# define the recommendation function\n",
    "def recommend_movie(USER_ID,NUMBER_RECO):\n",
    "\n",
    "    last_movie_seen=user_movies[user_movies.userId==USER_ID].iloc[-1]['imdbId']\n",
    "    user_movies.loc[:,\"last_seen\"]=last_movie_seen\n",
    "\n",
    "    #form user_can_rate dataframe\n",
    "    user_rated = user_movies[user_movies['userId']==USER_ID]\n",
    "    user_can_rate = user_movies[ ~user_movies.imdbId.isin (user_rated[\"imdbId\"])]\n",
    "    user_can_rate.loc[:,\"userId\"]=USER_ID\n",
    "    user_can_rate= user_can_rate.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # form the features datafram\n",
    "    cat_cols__ = user_can_rate.drop(columns=['userId', 'imdbId', 'last_seen'])\n",
    "    agg_history__ = user_can_rate[['userId']].merge(rating_history_norm, left_on='userId', right_index=True) \n",
    "    active_groups__ = active_ohe.transform(user_can_rate[['userId','imdbId','last_seen']]) \n",
    "    features = np.hstack((active_groups__, agg_history__.iloc[:,1:], cat_cols__))\n",
    "\n",
    "    # predcit using the model\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y = model(features_tensor)\n",
    "\n",
    "    # form a sorted list of the top n movies\n",
    "    ratingss=y.numpy().round(2).reshape(-1,1)\n",
    "    movies=user_can_rate['imdbId'].values.reshape(-1,1)\n",
    "    result = np.concatenate((ratingss, movies), axis=1)\n",
    "\n",
    "    return result[np.argsort(result[:, 0][::-1])][:NUMBER_RECO,1].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 386588,  422618, 1082588, 1714208, 1055366,  166110,   32553,\n",
       "        259446,   97981,  454824])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_movie(359,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([ 758752,   55257,   91064,   97493, 1545660])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMED OSAMA\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.4.1.post1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# import the datasets\n",
    "user_movies = pd.read_csv(\"user_movies.csv\")\n",
    "rating_history_norm = pd.read_csv(\"rating_history_norm.csv\", index_col=0)\n",
    "with open('one_hot_encoder_sec.pkl', 'rb') as f:\n",
    "    active_ohe = pickle.load(f)\n",
    "\n",
    "\n",
    "class FactorizationMachine:\n",
    "    def __init__(self, n, k):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.linear_weights = np.random.randn(n, 1)\n",
    "        self.V = np.random.randn(n, k)  # Factor matrix\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        part_1 = np.sum(np.dot(x_batch, self.V) ** 2, axis=1, keepdims=True)\n",
    "        part_2 = np.sum(np.dot(x_batch ** 2, self.V ** 2), axis=1, keepdims=True)\n",
    "        inter_term = 0.5 * (part_1 - part_2)\n",
    "        var_strength = np.dot(x_batch, self.linear_weights.T)\n",
    "        return var_strength + inter_term\n",
    "        return var_strength \n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.linear_weights = np.array(state_dict['linear_weights'])\n",
    "        self.V = np.array(state_dict['V'])\n",
    "\n",
    "\n",
    "# Load the model parameters from a file\n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        state_dict = pickle.load(f)\n",
    "    model = FactorizationMachine(n=29721, k=20)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "model = load_model('model_cola_pickle_numpy.pkl')\n",
    "\n",
    "\n",
    "# define the recommendation function\n",
    "def recommend_movie(USER_ID, NUMBER_RECO):\n",
    "    last_movie_seen = user_movies[user_movies.userId == USER_ID].iloc[-1]['imdbId']\n",
    "    user_movies.loc[:, \"last_seen\"] = last_movie_seen\n",
    "\n",
    "    # Form user_can_rate dataframe\n",
    "    user_rated = user_movies[user_movies['userId'] == USER_ID]\n",
    "    user_can_rate = user_movies[~user_movies.imdbId.isin(user_rated[\"imdbId\"])]\n",
    "    user_can_rate.loc[:, \"userId\"] = USER_ID\n",
    "    user_can_rate = user_can_rate.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Form the features dataframe\n",
    "    cat_cols__ = user_can_rate.drop(columns=['userId', 'imdbId', 'last_seen'])\n",
    "    agg_history__ = user_can_rate[['userId']].merge(rating_history_norm, left_on='userId', right_index=True)\n",
    "    active_groups__ = active_ohe.transform(user_can_rate[['userId', 'imdbId', 'last_seen']])\n",
    "    features = np.hstack((active_groups__, agg_history__.iloc[:, 1:], cat_cols__))\n",
    "\n",
    "    # Predict using the model\n",
    "    features_np = np.array(features, dtype=np.float32)\n",
    "    y = model.forward(features_np)\n",
    "\n",
    "    # Form a sorted list of the top n movies\n",
    "    ratings = y.round(2).reshape(-1, 1)\n",
    "    movies = user_can_rate['imdbId'].values.reshape(-1, 1)\n",
    "    result = np.concatenate((ratings, movies), axis=1)\n",
    "\n",
    "    return result[np.argsort(result[:, 0])[::-1]][:NUMBER_RECO, 1].astype(int)\n",
    "    # return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 424755, 1677561,  100339,   93871, 1067106,  239655, 2375574,\n",
       "         95875,   83806,  104740])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "recommend_movie(359,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([ 424755,  109402, 1517252,  825283,   95875])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([  91064,  758752,   55257, 1545660,   97493])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model parameters as a pickle file and a NumPy file for deployment\n",
    "\n",
    "# import torch\n",
    "\n",
    "# class FactorizationMachine(torch.nn.Module):\n",
    "#     def __init__(self, n, k, bias=False):\n",
    "#         super(FactorizationMachine, self).__init__()\n",
    "#         self.n = n\n",
    "#         self.k = k\n",
    "#         self.linear = torch.nn.Linear(self.n, 1, bias)\n",
    "#         self.V = torch.nn.Parameter(torch.randn(n, k))  \n",
    "#     def forward(self, x_batch):\n",
    "#         part_1 = torch.sum(torch.mm(x_batch, self.V).pow(2), dim=1, keepdim=True)\n",
    "#         part_2 = torch.sum(torch.mm(x_batch.pow(2), self.V.pow(2)), dim=1, keepdim=True)\n",
    "#         inter_term = 0.5 * (part_1 - part_2)\n",
    "#         var_strength = self.linear(x_batch)\n",
    "#         return var_strength + inter_term\n",
    "\n",
    "\n",
    "# model=FactorizationMachine(n=29721, k=20)\n",
    "# model.load_state_dict(torch.load('model_cola.pt'))\n",
    "\n",
    "\n",
    "# state_dict = {\n",
    "#     'linear_weights': model.linear.weight.tolist(),\n",
    "#     'V': model.V.detach().numpy()\n",
    "# }\n",
    "\n",
    "# with open('model_cola_pickle_numpy.pkl', 'wb') as f:\n",
    "#     pickle.dump(state_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# import the datasets\n",
    "user_movies = pd.read_csv(\"user_movies.csv\")\n",
    "rating_history_norm = pd.read_csv(\"rating_history_norm.csv\", index_col=0)\n",
    "with open('one_hot_encoder_sec.pkl', 'rb') as f:\n",
    "    active_ohe = pickle.load(f)\n",
    "\n",
    "\n",
    "class FactorizationMachine:\n",
    "    def __init__(self, n, k):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.linear_weights = np.random.randn(n, 1)\n",
    "        self.V = np.random.randn(n, k)  # Factor matrix\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        part_1 = np.sum(np.dot(x_batch, self.V) ** 2, axis=1, keepdims=True)\n",
    "        part_2 = np.sum(np.dot(x_batch ** 2, self.V ** 2), axis=1, keepdims=True)\n",
    "        inter_term = 0.5 * (part_1 - part_2)\n",
    "        var_strength = np.dot(x_batch, self.linear_weights.T)\n",
    "        return var_strength + inter_term\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.linear_weights = np.array(state_dict['linear_weights'])\n",
    "        self.V = np.array(state_dict['V'])\n",
    "\n",
    "\n",
    "# Load the model parameters from a file\n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        state_dict = pickle.load(f)\n",
    "    model = FactorizationMachine(n=29721, k=20)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "model = load_model('model_cola_pickle_numpy.pkl')\n",
    "\n",
    "\n",
    "# define the recommendation function\n",
    "USER_ID = 8\n",
    "\n",
    "NUMBER_RECO = 10\n",
    "\n",
    "\n",
    "last_movie_seen = user_movies[user_movies.userId == USER_ID].iloc[-1]['imdbId']\n",
    "user_movies.loc[:, \"last_seen\"] = last_movie_seen\n",
    "\n",
    "# Form user_can_rate dataframe\n",
    "user_rated = user_movies[user_movies['userId'] == USER_ID]\n",
    "user_can_rate = user_movies[~user_movies.imdbId.isin(user_rated[\"imdbId\"])]\n",
    "user_can_rate.loc[:, \"userId\"] = USER_ID\n",
    "user_can_rate = user_can_rate.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Form the features dataframe\n",
    "cat_cols__ = user_can_rate.drop(columns=['userId', 'imdbId', 'last_seen'])\n",
    "agg_history__ = user_can_rate[['userId']].merge(rating_history_norm, left_on='userId', right_index=True)\n",
    "active_groups__ = active_ohe.transform(user_can_rate[['userId', 'imdbId', 'last_seen']])\n",
    "features = np.hstack((active_groups__, agg_history__.iloc[:, 1:], cat_cols__))\n",
    "\n",
    "# Predict using the model\n",
    "features_np = np.array(features, dtype=np.float32)\n",
    "y = model.forward(features_np)\n",
    "\n",
    "# Form a sorted list of the top n movies\n",
    "ratings = y.round(2).reshape(-1, 1)\n",
    "movies = user_can_rate['imdbId'].values.reshape(-1, 1)\n",
    "result = np.concatenate((ratings, movies), axis=1)\n",
    "\n",
    "result =  result[np.argsort(result[:, 0])[::-1]][:NUMBER_RECO, 1].astype(int)\n",
    "# return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = 8\n",
    "\n",
    "NUMBER_RECO = 10\n",
    "\n",
    "\n",
    "last_movie_seen = user_movies[user_movies.userId == USER_ID].iloc[-1]['imdbId']\n",
    "user_movies.loc[:, \"last_seen\"] = last_movie_seen\n",
    "\n",
    "# Form user_can_rate dataframe\n",
    "user_rated = user_movies[user_movies['userId'] == USER_ID]\n",
    "user_can_rate = user_movies[~user_movies.imdbId.isin(user_rated[\"imdbId\"])]\n",
    "user_can_rate.loc[:, \"userId\"] = USER_ID\n",
    "user_can_rate = user_can_rate.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Form the features dataframe\n",
    "cat_cols__ = user_can_rate.drop(columns=['userId', 'imdbId', 'last_seen'])\n",
    "agg_history__ = user_can_rate[['userId']].merge(rating_history_norm, left_on='userId', right_index=True)\n",
    "active_groups__ = active_ohe.transform(user_can_rate[['userId', 'imdbId', 'last_seen']])\n",
    "features = np.hstack((active_groups__, agg_history__.iloc[:, 1:], cat_cols__))\n",
    "\n",
    "# Predict using the model\n",
    "features_np = np.array(features, dtype=np.float32)\n",
    "# y = model.forward(features_np)\n",
    "\n",
    "# # Form a sorted list of the top n movies\n",
    "# ratings = y.round(2).reshape(-1, 1)\n",
    "# movies = user_can_rate['imdbId'].values.reshape(-1, 1)\n",
    "# result = np.concatenate((ratings, movies), axis=1)\n",
    "\n",
    "# result =  result[np.argsort(result[:, 0])[::-1]][:NUMBER_RECO, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23161049,  0.16279529, -0.32845557, ...,  0.06948352,\n",
       "        -0.56501   ,  0.40879342],\n",
       "       [ 0.02308583, -0.09877924, -0.05107058, ...,  0.07289457,\n",
       "        -0.00310018,  0.02678443],\n",
       "       [-0.12866688,  0.3054938 ,  0.1358318 , ...,  0.08835667,\n",
       "         0.12933207, -0.69142413],\n",
       "       ...,\n",
       "       [-0.17398903,  0.21960019, -0.13789454, ..., -0.34476689,\n",
       "        -0.05934772, -0.32462913],\n",
       "       [ 0.08348624, -0.25757474,  0.18738982, ...,  0.0300645 ,\n",
       "         0.14736415,  0.319353  ],\n",
       "       [-0.11154244, -0.15386644, -0.37823576, ..., -0.20922843,\n",
       "        -0.16290176, -0.03436306]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 424755, 1517252,  385586,  104740,  130414, 1677561,  420901,\n",
       "       1067106,  108941, 2375574])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_batch = features_np\n",
    "\n",
    "part_1 = np.sum(np.dot(x_batch, model.V) ** 2, axis=1, keepdims=True)\n",
    "part_2 = np.sum(np.dot(x_batch ** 2, model.V ** 2), axis=1, keepdims=True)\n",
    "inter_term = 0.5 * (part_1 - part_2)\n",
    "var_strength = np.dot(x_batch, model.linear_weights.T)\n",
    "y= var_strength + inter_term\n",
    "\n",
    "ratings = y.round(2).reshape(-1, 1)\n",
    "movies = user_can_rate['imdbId'].values.reshape(-1, 1)\n",
    "result = np.concatenate((ratings, movies), axis=1)\n",
    "\n",
    "result =  result[np.argsort(result[:, 0])[::-1]][:NUMBER_RECO, 1].astype(int)\n",
    "result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9677,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.dot(x_batch ** 2, model.V ** 2), axis=1).shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9677, 29721)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29721, 20])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29721, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear_weights.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4,5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
